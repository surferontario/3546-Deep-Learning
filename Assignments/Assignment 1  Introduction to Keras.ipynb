{
  "cells": [
    {
      "metadata": {
        "_uuid": "3bf66182e4e6573d2bf54ffb99869a9ae11fdc9d"
      },
      "cell_type": "markdown",
      "source": "Assignment 1 - Deep Learning using Keras\n\nSCS_3546_002 Deep Learning, University of Toronto\n\nDeveloped by Ashish Gupta"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras import layers",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "**Create a sequential model with an input layer, 2 hidden layers and one output layer (all Dense):**\n\nThe input layer should have 64 units and shape (10, ) and use relu.\nThe first hidden layer should have 32 units and use a sigmoid activation\nThe second hidden layer should have 5 units and use relu with an L2 kernel regularization factor of 0.01\nThe output layer should produce three outputs using softmax"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a90e1ae8a7076f574c62306a2f9a4fc91612ebb"
      },
      "cell_type": "code",
      "source": "sequential_model = tf.keras.Sequential()\n\n# Add an input layer should have 64 units and shape (10, ) and use relu\nsequential_model.add(layers.Dense(64, activation='relu',input_shape=(10,)))\n\n#The first hidden layer should have 32 units and use a sigmoid activation\nsequential_model.add(layers.Dense(32, activation=tf.sigmoid))\n\n#The second hidden layer should have 5 units and use relu with an L2 kernel regularization factor of 0.01\nsequential_model.add(layers.Dense(5, bias_regularizer=tf.keras.regularizers.l2(0.01)))\n\n#The output layer should produce three outputs using softmax\nsequential_model.add(layers.Dense(3, activation='softmax'))",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c5850d7455401bd48929e7e171f9e036ddb675c2"
      },
      "cell_type": "markdown",
      "source": "Train the model using the RMSProp optimizer with a factor of 0.01, a loss function of Mean Squared Error and a metric of Mean Absolute Error"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eda28ff93e358aaa6a4d657431dc6bd5e6ce438a"
      },
      "cell_type": "code",
      "source": "# Configure a model for categorical classification.\nsequential_model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n                         loss='mse',       # mean squared error\n                         metrics=['mae'])  # mean absolute error",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fb6c0c53c5d8ff326378605d506e0d9d8cdea20f"
      },
      "cell_type": "markdown",
      "source": "Input NumPy data, \nTrain for 10 epochs using a batch size of 32. \nUse a randomly-generated validation set similar to the example."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f91e7b16eb3c060be7c4432dbbee67e396af170"
      },
      "cell_type": "code",
      "source": "data = np.random.random((1000, 10))\nlabels = np.random.random((1000, 3)) # 3 Labels rather than 10\n\nval_data = np.random.random((100, 10))\nval_labels = np.random.random((100, 3))\n\n#rain for 10 epochs using a batch size of 32. Use a randomly-generated validation set similar to the example.\n#sequential_model.fit(data, labels, epochs=10, batch_size=32)\n\ndataset = tf.data.Dataset.from_tensor_slices((data, labels))\ndataset = dataset.batch(32).repeat()\n\nval_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\nval_dataset = val_dataset.batch(32).repeat()\n\nsequential_model.fit(dataset, epochs=10, steps_per_epoch=30,\n          validation_data=val_dataset,\n          validation_steps=3)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/10\n30/30 [==============================] - 0s 12ms/step - loss: 0.1223 - mean_absolute_error: 0.2886 - val_loss: 0.1299 - val_mean_absolute_error: 0.2976\nEpoch 2/10\n30/30 [==============================] - 0s 2ms/step - loss: 0.1099 - mean_absolute_error: 0.2740 - val_loss: 0.1257 - val_mean_absolute_error: 0.3030\nEpoch 3/10\n30/30 [==============================] - 0s 2ms/step - loss: 0.1093 - mean_absolute_error: 0.2739 - val_loss: 0.1343 - val_mean_absolute_error: 0.3144\nEpoch 4/10\n30/30 [==============================] - 0s 2ms/step - loss: 0.1112 - mean_absolute_error: 0.2762 - val_loss: 0.1328 - val_mean_absolute_error: 0.3041\nEpoch 5/10\n30/30 [==============================] - 0s 2ms/step - loss: 0.1108 - mean_absolute_error: 0.2758 - val_loss: 0.1219 - val_mean_absolute_error: 0.2894\nEpoch 6/10\n30/30 [==============================] - 0s 2ms/step - loss: 0.1108 - mean_absolute_error: 0.2757 - val_loss: 0.1274 - val_mean_absolute_error: 0.3044\nEpoch 7/10\n30/30 [==============================] - 0s 1ms/step - loss: 0.1097 - mean_absolute_error: 0.2739 - val_loss: 0.1323 - val_mean_absolute_error: 0.3125\nEpoch 8/10\n30/30 [==============================] - 0s 1ms/step - loss: 0.1087 - mean_absolute_error: 0.2721 - val_loss: 0.1262 - val_mean_absolute_error: 0.3011\nEpoch 9/10\n30/30 [==============================] - 0s 1ms/step - loss: 0.1080 - mean_absolute_error: 0.2716 - val_loss: 0.1227 - val_mean_absolute_error: 0.2896\nEpoch 10/10\n30/30 [==============================] - 0s 1ms/step - loss: 0.1082 - mean_absolute_error: 0.2718 - val_loss: 0.1261 - val_mean_absolute_error: 0.3034\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f0eac2ba780>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "3a4801d255cb3308e3075e0ad951d800b72259ed"
      },
      "cell_type": "markdown",
      "source": "Now Evaluate and Predict"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7c208d95637c6e26a2e08cbad9181de5682e6119"
      },
      "cell_type": "code",
      "source": "data = np.random.random((1000, 10))\nlabels = np.random.random((1000, 3))\n\nsequential_model.evaluate(data, labels, batch_size=32)\n\nsequential_model.evaluate(dataset, steps=30)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "1000/1000 [==============================] - 0s 81us/step\n30/30 [==============================] - 0s 4ms/step\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "[0.10817250286539395, 0.2723219538728396]"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}